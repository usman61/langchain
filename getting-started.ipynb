{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"]= OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5383/3031472346.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI()\n",
      "/tmp/ipykernel_5383/3031472346.py:2: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  name = llm(\"I want to open a restaurant for Pakistani food. Suggest a fency names for this\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"Spice of Pakistan\"\n",
      "2. \"Taste of Lahore\"\n",
      "3. \"Pakistani Palate\"\n",
      "4. \"Flavors of Karachi\"\n",
      "5. \"Saffron Delight\"\n",
      "6. \"Pakistani Bites\"\n",
      "7. \"Chai & Kabab House\"\n",
      "8. \"Punjab Tandoori\"\n",
      "9. \"Sultan's Feast\"\n",
      "10. \"Desi Diner\"\n",
      "11. \"Chaat Corner\"\n",
      "12. \"Curry Kingdom\"\n",
      "13. \"Karachi Kitchen\"\n",
      "14. \"Lahori Lounge\"\n",
      "15. \"Peshawari Platter\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = OpenAI()\n",
    "name = llm(\"I want to open a restaurant for Pakistani food. Suggest a fency names for this\")\n",
    "print(name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this\"\n",
    ")\n",
    "# prompt_template_name.format(cuisine = \"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5383/3257458736.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm = llm,prompt = prompt_template_name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'German', 'text': '\\n\\n\"Kaiser\\'s Kitchen\" '}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm = llm,prompt = prompt_template_name)\n",
    "chain.invoke(\"German\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this\"\n",
    ")\n",
    "name_chain = LLMChain(llm = llm,prompt = prompt_template_name)\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comman separated\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm = llm,prompt = prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " string\n",
      "\n",
      "1. Chicken Biryani\n",
      "2. Beef Kebabs\n",
      "3. Palak Paneer\n",
      "4. Tandoori Chicken\n",
      "5. Lamb Curry\n",
      "6. Vegetable Samosas\n",
      "7. Naan Bread\n",
      "8. Aloo Gobi\n",
      "9. Chicken Tikka Masala\n",
      "10. Mango Lassi\n",
      "11. Haleem\n",
      "12. Daal Makhani\n",
      "13. Chicken Karahi\n",
      "14. Seekh Kabab\n",
      "15. Chana Masala\n",
      "16. Shrimp Biryani\n",
      "17. Kheer (Rice Pudding)\n",
      "18. Aloo Keema (Potato and Minced Meat Curry)\n",
      "19. Chicken Handi\n",
      "20. Gulab Jamun (Fried Milk Balls in Syrup)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[name_chain,food_items_chain])\n",
    "response = chain.run(\"Pakistani\")\n",
    "print(response) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this\"\n",
    ")\n",
    "name_chain = LLMChain(llm = llm,prompt = prompt_template_name,output_key=\"restaurant_name\")\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comman separated\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm = llm,prompt = prompt_template_items,output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5383/3976091021.py:8: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({\"cuisine\":\"Arabic\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': '\\n\\n\"Al-Fakhira\" (meaning \"The Pride\" in Arabic) ',\n",
       " 'menu_items': ' string\\n\\n1. Hummus platter with pita bread\\n2. Falafel wrap with tahini sauce\\n3. Grilled chicken kabobs with saffron rice\\n4. Lamb shawarma with garlic aioli\\n5. Fattoush salad with pomegranate dressing\\n6. Baba ghanoush with fresh vegetables\\n7. Beef kofta with tzatziki sauce\\n8. Stuffed grape leaves with yogurt dip\\n9. Lentil soup with warm pita bread\\n10. Baklava for dessert\\n11. Tabouleh salad with fresh herbs and lemon dressing\\n12. Chicken shawarma platter with rice and hummus\\n13. Grilled halloumi cheese with fig jam\\n14. Shawarma fries with garlic sauce\\n15. Moroccan mint tea for a refreshing drink.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[name_chain,food_items_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\",\"menu_items\"]\n",
    ")\n",
    "chain({\"cuisine\":\"Arabic\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
