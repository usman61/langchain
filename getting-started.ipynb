{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"]= OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5383/3031472346.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI()\n",
      "/tmp/ipykernel_5383/3031472346.py:2: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  name = llm(\"I want to open a restaurant for Pakistani food. Suggest a fency names for this\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"Spice of Pakistan\"\n",
      "2. \"Taste of Lahore\"\n",
      "3. \"Pakistani Palate\"\n",
      "4. \"Flavors of Karachi\"\n",
      "5. \"Saffron Delight\"\n",
      "6. \"Pakistani Bites\"\n",
      "7. \"Chai & Kabab House\"\n",
      "8. \"Punjab Tandoori\"\n",
      "9. \"Sultan's Feast\"\n",
      "10. \"Desi Diner\"\n",
      "11. \"Chaat Corner\"\n",
      "12. \"Curry Kingdom\"\n",
      "13. \"Karachi Kitchen\"\n",
      "14. \"Lahori Lounge\"\n",
      "15. \"Peshawari Platter\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = OpenAI()\n",
    "name = llm(\"I want to open a restaurant for Pakistani food. Suggest a fency names for this\")\n",
    "print(name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this\"\n",
    ")\n",
    "# prompt_template_name.format(cuisine = \"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5383/3257458736.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm = llm,prompt = prompt_template_name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'German', 'text': '\\n\\n\"Kaiser\\'s Kitchen\" '}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm = llm,prompt = prompt_template_name)\n",
    "chain.invoke(\"German\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this\"\n",
    ")\n",
    "name_chain = LLMChain(llm = llm,prompt = prompt_template_name)\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comman separated\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm = llm,prompt = prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " string\n",
      "\n",
      "1. Chicken Biryani\n",
      "2. Beef Kebabs\n",
      "3. Palak Paneer\n",
      "4. Tandoori Chicken\n",
      "5. Lamb Curry\n",
      "6. Vegetable Samosas\n",
      "7. Naan Bread\n",
      "8. Aloo Gobi\n",
      "9. Chicken Tikka Masala\n",
      "10. Mango Lassi\n",
      "11. Haleem\n",
      "12. Daal Makhani\n",
      "13. Chicken Karahi\n",
      "14. Seekh Kabab\n",
      "15. Chana Masala\n",
      "16. Shrimp Biryani\n",
      "17. Kheer (Rice Pudding)\n",
      "18. Aloo Keema (Potato and Minced Meat Curry)\n",
      "19. Chicken Handi\n",
      "20. Gulab Jamun (Fried Milk Balls in Syrup)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[name_chain,food_items_chain])\n",
    "response = chain.run(\"Pakistani\")\n",
    "print(response) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this\"\n",
    ")\n",
    "name_chain = LLMChain(llm = llm,prompt = prompt_template_name,output_key=\"restaurant_name\")\n",
    "\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comman separated\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm = llm,prompt = prompt_template_items,output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5383/3976091021.py:8: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({\"cuisine\":\"Arabic\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': '\\n\\n\"Al-Fakhira\" (meaning \"The Pride\" in Arabic) ',\n",
       " 'menu_items': ' string\\n\\n1. Hummus platter with pita bread\\n2. Falafel wrap with tahini sauce\\n3. Grilled chicken kabobs with saffron rice\\n4. Lamb shawarma with garlic aioli\\n5. Fattoush salad with pomegranate dressing\\n6. Baba ghanoush with fresh vegetables\\n7. Beef kofta with tzatziki sauce\\n8. Stuffed grape leaves with yogurt dip\\n9. Lentil soup with warm pita bread\\n10. Baklava for dessert\\n11. Tabouleh salad with fresh herbs and lemon dressing\\n12. Chicken shawarma platter with rice and hummus\\n13. Grilled halloumi cheese with fig jam\\n14. Shawarma fries with garlic sauce\\n15. Moroccan mint tea for a refreshing drink.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[name_chain,food_items_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\",\"menu_items\"]\n",
    ")\n",
    "chain({\"cuisine\":\"Arabic\"})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tool llm-math requires an LLM to be provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllms\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m OpenAI\n\u001b[1;32m      4\u001b[0m llm \u001b[39m=\u001b[39m OpenAI(temperature\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m tools \u001b[39m=\u001b[39m load_tools([\u001b[39m\"\u001b[39;49m\u001b[39mwikipedia\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mllm-math\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      7\u001b[0m agent \u001b[39m=\u001b[39m initialize_agent(\n\u001b[1;32m      8\u001b[0m     tools,\n\u001b[1;32m      9\u001b[0m     llm,\n\u001b[1;32m     10\u001b[0m     agent\u001b[39m=\u001b[39mAgentType\u001b[39m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     13\u001b[0m agent\u001b[39m.\u001b[39mrun(\u001b[39m\"\u001b[39m\u001b[39mWhen was Elon Musk born? What is his age right now in 2025\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain_community/agent_toolkits/load_tools.py:734\u001b[0m, in \u001b[0;36mload_tools\u001b[0;34m(tool_names, llm, callbacks, allow_dangerous_tools, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m _LLM_TOOLS:\n\u001b[1;32m    733\u001b[0m     \u001b[39mif\u001b[39;00m llm \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 734\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTool \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m requires an LLM to be provided\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    735\u001b[0m     tool \u001b[39m=\u001b[39m _LLM_TOOLS[name](llm)\n\u001b[1;32m    736\u001b[0m     tools\u001b[39m.\u001b[39mappend(tool)\n",
      "\u001b[0;31mValueError\u001b[0m: Tool llm-math requires an LLM to be provided"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType,initialize_agent,load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.6)\n",
    "tools = load_tools([\"wikipedia\",\"llm-math\"])\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    "    )\n",
    "\n",
    "agent.run(\"When was Elon Musk born? What is his age right now in 2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4 (from wikipedia)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/usman/anaconda3/envs/langchain/lib/python3.10/site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/usman/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/usman/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/usman/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/usman/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.12.14)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->wikipedia)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=a32ff17ab6aec6cf34250db980c7ee525e43d33988484b6202c4428915813fba\n",
      "  Stored in directory: /home/usman/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6 wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
